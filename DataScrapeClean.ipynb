{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lxml\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section will scrape IMDB and Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this functions creates the list of URLS based on size of films entered\n",
    "def createURLs(numMovies): \n",
    "    \"\"\"Create and return two lists of URLS given the number of entries desired\n",
    "        Keyword Arguments:\n",
    "        numMovies- the number of movies you want to scrape\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    url_range_imdb = range(1,numMovies,50) #create imdb range\n",
    "    url_range_boxoffice = range(1,numMovies,200) #create box office mojo range\n",
    "    url_imdb = []\n",
    "    url_boxoffice = []\n",
    "    for i in url_range_imdb: #create list of imdb urls\n",
    "        url_imdb.append(\"https://www.imdb.com/search/title/?title_type=feature&start=\" + str(i) + \"&ref_=adv_prv\")\n",
    "    for i in url_range_boxoffice: #create list of box offic emojo urls\n",
    "        if i == 1:\n",
    "            url_boxoffice.append(\"https://www.boxofficemojo.com/chart/top_lifetime_gross/\")\n",
    "        else:\n",
    "            url_boxoffice.append(\"https://www.boxofficemojo.com/chart/top_lifetime_gross/?offset=\" + str(i-1))\n",
    "    #creates a list of the urls to scrape from. Each page shows 50 results and starts from 1\n",
    "    return (url_imdb, url_boxoffice) # return URLS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lists\n",
    "title = []\n",
    "date = []\n",
    "genre = []\n",
    "rating = []\n",
    "score = []\n",
    "director = []\n",
    "stars = []\n",
    "#loop through each url\n",
    "url_list = createURLs(10000)\n",
    "for url in url_list[0]:\n",
    "    #grab the data from the url, read it into Beauitufl soup, find each movie from the page\n",
    "    page = get(url)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    content = soup.find(id=\"main\") #grab the main content\n",
    "    frames = content.find_all(\"div\", class_=\"lister-item mode-advanced\") #grab each movie intsance\n",
    "    for frame in frames:    \n",
    "        #grab data from each movie instance\n",
    "        firstLine = frame.find(\"h3\", class_=\"lister-item-header\")\n",
    "        title.append(firstLine.find(\"a\").text)\n",
    "        date.append(re.sub(r\"[()]\",\"\", firstLine.find_all(\"span\")[-1].text))\n",
    "        try:\n",
    "            genre.append(frame.find(\"span\", class_=\"genre\").text.rstrip().replace(\"\\n\",\"\").split(\",\"))\n",
    "        except:\n",
    "            genre.append('None')\n",
    "        try:\n",
    "            rating.append(frame.find(\"strong\").text)\n",
    "        except:\n",
    "            rating.append(0.0) #set rating to 0.0 if its not there\n",
    "        try:\n",
    "            score.append(frame.find(\"span\", class_=\"metascore favorable\").text.rstrip())\n",
    "        except:\n",
    "            try:\n",
    "                score.append(frame.find(\"span\", class_=\"metascore unfavorable\").text.rstrip())\n",
    "            except:\n",
    "                try:\n",
    "                    score.append(frame.find(\"span\", class_=\"metascore mixed\").text.rstrip())\n",
    "                except:\n",
    "                    score.append(0.0) #set score to 0.0 if it doesnt exist\n",
    "        cast = (frame.find(\"p\", class_=\"\"))\n",
    "        try:    #split apart the director and the casts\n",
    "            casts = cast.text.replace(\"\\n\",\"\").split('|')\n",
    "            casts = [x.strip() for x in casts]\n",
    "            casts = [casts[i].replace(j, \"\") for i,j in enumerate([\"Director:\", \"Stars:\"])]\n",
    "            director.append(casts[0])\n",
    "            stars.append([x.strip() for x in casts[1].split(\",\")])\n",
    "        except:    #set director to 'No Director' if it isnt there\n",
    "            casts = cast.text.replace(\"\\n\",\"\").strip()\n",
    "            director.append(\"No Director\")\n",
    "            stars.append([x.strip() for x in casts.split(\",\")])\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe\n",
    "column_names = ['Title','Year','Genre','Rating','Score','Director','Stars'] \n",
    "df = pd.DataFrame(list(zip(title,date,genre,rating,score,director,stars)),columns = column_names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scrape box office mojo\n",
    "titles = []\n",
    "gross = []\n",
    "years = []\n",
    "for url in url_list[1]:\n",
    "    page = get(url)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    rows = soup.findAll('tr')\n",
    "    i=0\n",
    "    for row in rows:\n",
    "        if i == 0:\n",
    "            i=1\n",
    "        else:\n",
    "            titles.append(row.find(class_='a-link-normal').text)\n",
    "            gross.append(row.find(class_='a-text-right mojo-field-type-money').text)\n",
    "            years.append(row.find(class_='a-text-left mojo-field-type-year').text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn it into a dataframe\n",
    "df2 = pd.DataFrame(list(zip(titles,gross,years)),columns = ['Title','Gross','Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes\n",
    "merged_df= pd.merge(left = df, right = df2, on = ['Title','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Comedy,  Drama,  Thriller]</td>\n",
       "      <td>8.6</td>\n",
       "      <td>96</td>\n",
       "      <td>Bong Joon Ho</td>\n",
       "      <td>[Kang-ho Song, Sun-kyun Lee, Yeo-jeong Jo, Woo...</td>\n",
       "      <td>$51,809,136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Invisible Man</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Horror,  Mystery,  Sci-Fi]</td>\n",
       "      <td>7.6</td>\n",
       "      <td>71</td>\n",
       "      <td>Leigh Whannell</td>\n",
       "      <td>[Elisabeth Moss, Oliver Jackson-Cohen, Harriet...</td>\n",
       "      <td>$33,738,175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Knives Out</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Comedy,  Crime,  Drama]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82</td>\n",
       "      <td>Rian Johnson</td>\n",
       "      <td>[Daniel Craig, Chris Evans, Ana de Armas, Jami...</td>\n",
       "      <td>$164,698,675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sonic the Hedgehog</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Action,  Adventure,  Comedy]</td>\n",
       "      <td>6.8</td>\n",
       "      <td>47</td>\n",
       "      <td>Jeff Fowler</td>\n",
       "      <td>[Ben Schwartz, James Marsden, Jim Carrey, Tika...</td>\n",
       "      <td>$131,060,702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jojo Rabbit</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Comedy,  Drama,  War]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Taika Waititi</td>\n",
       "      <td>[Roman Griffin Davis, Thomasin McKenzie, Scarl...</td>\n",
       "      <td>$33,176,865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Title  Year                          Genre Rating Score  \\\n",
       "0            Parasite  2019    [Comedy,  Drama,  Thriller]    8.6    96   \n",
       "1   The Invisible Man  2020    [Horror,  Mystery,  Sci-Fi]    7.6    71   \n",
       "2          Knives Out  2019       [Comedy,  Crime,  Drama]    8.0    82   \n",
       "3  Sonic the Hedgehog  2020  [Action,  Adventure,  Comedy]    6.8    47   \n",
       "4         Jojo Rabbit  2019         [Comedy,  Drama,  War]    8.0    58   \n",
       "\n",
       "         Director                                              Stars  \\\n",
       "0    Bong Joon Ho  [Kang-ho Song, Sun-kyun Lee, Yeo-jeong Jo, Woo...   \n",
       "1  Leigh Whannell  [Elisabeth Moss, Oliver Jackson-Cohen, Harriet...   \n",
       "2    Rian Johnson  [Daniel Craig, Chris Evans, Ana de Armas, Jami...   \n",
       "3     Jeff Fowler  [Ben Schwartz, James Marsden, Jim Carrey, Tika...   \n",
       "4   Taika Waititi  [Roman Griffin Davis, Thomasin McKenzie, Scarl...   \n",
       "\n",
       "          Gross  \n",
       "0   $51,809,136  \n",
       "1   $33,738,175  \n",
       "2  $164,698,675  \n",
       "3  $131,060,702  \n",
       "4   $33,176,865  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gross'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gross'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-31fd53b10736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Clean the Gross and Genre columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gross'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gross'"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "#Clean the Gross and Genre columns\n",
    "df['Gross'] = df['Gross'].astype(str)\n",
    "df['Gross'] = df['Gross'].apply(lambda x: x.replace(',',''))\n",
    "df['Gross'] = df['Gross'].apply(lambda x: x.replace('$',''))\n",
    "df['Gross'] = df['Gross'].astype(int)\n",
    "df['Genre'] = df['Genre'].apply(lambda x:x.strip('['))\n",
    "df['Genre'] = df['Genre'].apply(lambda x:x.strip(']'))\n",
    "df['Genre'] = df['Genre'].apply(lambda x:x.replace(\"'\",''))\n",
    "df['Genre'] = df['Genre'].apply(lambda x:x.replace(\",\",''))\n",
    "df['Genre'] = df['Genre'].apply(lambda x:x.replace(\"  \",' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to csv\n",
    "df.to_csv('movieData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section uses an API to get data from the Movie DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve theMovieDB.org API key\n",
    "def get_keys(fname):\n",
    "    '''\n",
    "    Init signature: \n",
    "        get_keys(fname)\n",
    "    Docstring:     \n",
    "        get_keys(filename='') -> dict\n",
    "        Retrieve API key stored on file.  return a dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname: \n",
    "        json file name where the API key is stored.\n",
    "      \n",
    "    '''\n",
    "    with open(fname) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the api key for movieDB using the get_keys function\n",
    "keys = get_keys('moviedb.json')\n",
    "\n",
    "# Assign API value to variable\n",
    "api_key = keys['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Function get_mtdb_movies explainations:\n",
    "\n",
    "The Movie DB web site provides an API to pull data from their source. However, they have a retriction of supplying on 10,000 movies or 500 pages of movies titles.\n",
    "In order to collect all the movies, a for loop to issue the request for the movie data is a sound method.\n",
    "The function defines the neccessary request parameters based on the API requirements.\n",
    "In the for loop structure, we generate the respond obj, test the request status and proceed to create the dataframe on the first go. Subsequence passes, the new dataframe will be concatenated to the previous one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TMDB API to retrieve list of movies with primary_release_date greater than 01-01-2010\n",
    "def get_mtdb_movies():\n",
    "    '''\n",
    "    init signature:\n",
    "        get_mtdb_movies() \n",
    "    docstring:\n",
    "        get_mtdb_movies() -> dataframe\n",
    "        Using TMDB API to retrive a list of movies\n",
    "    '''\n",
    "    # Define get request parameters\n",
    "    url = 'https://api.themoviedb.org/3/discover/movie?'\n",
    "    langauge = 'en-US'\n",
    "    sort_by = 'popularity.desc'\n",
    "    include_adult = 'false'\n",
    "    include_video = 'false'\n",
    "    primary_release_date_gt = '2010-01-01'\n",
    "\n",
    "    url_param = {\n",
    "                    'api_key': api_key,\n",
    "                    'language': langauge,\n",
    "                    'sort_by': sort_by,\n",
    "                    'include_adult': include_adult,\n",
    "                    'include_video': include_video,\n",
    "                    'primary_release_date.gt': primary_release_date_gt\n",
    "                }\n",
    "\n",
    "    for i in range(1,500): \n",
    "        # update the page number using the iteration value and pass it to the request parameter\n",
    "        url_param.update({'page': i})\n",
    "        # create the response ojb.\n",
    "        resp = requests.get(url, params=url_param)\n",
    "        # condition to test if this is the first page\n",
    "        if resp.status_code == 200 and resp.json()['page'] == 1:\n",
    "            # create the DataFrame\n",
    "            df = pd.DataFrame.from_dict(resp.json()['results'])\n",
    "        # condition to test it is not the first page\n",
    "        elif resp.status_code == 200 and resp.json().get('page', 10000) < 10000:\n",
    "            # convert response to dataframe\n",
    "            a = pd.DataFrame.from_dict(resp.json()['results'])\n",
    "            # concat the present df (a) with the previous pass.  Note: without the sort parameter, concat fails.\n",
    "            df = pd.concat([df, a], sort=False)\n",
    "        # condition to test end of the page\n",
    "        elif resp.status_code == 200 and resp.json().get('page', 10000) == 10000:\n",
    "            break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the function to retrieve movie list from TMDB via their API and create a dataframe\n",
    "df = get_mtdb_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimension of the dataframe\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export initial df to csv since it is a lenghty process to import 500 requests\n",
    "df.to_csv('raw_tmdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset df index.  This will remove the duplicate index cause by the concaatenation of the df's\n",
    "df2 = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview df2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevent columns for the analysis (data cleaning process)\n",
    "df2.drop(['index', 'video', 'poster_path', 'adult', 'backdrop_path', 'overview'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking df2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the column names to use in the duplicated subset parameter\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for row duplication (data cleaning process).  Exclude column genre_ids becuase it contains list elements\n",
    "df2.duplicated(subset=['popularity', 'vote_count', 'id',\n",
    "                       'original_language', 'original_title',\n",
    "                       'title', 'vote_average', 'release_date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate title (data cleaning process)\n",
    "df2.title.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the duplicate titles.  Preview of the duplicate titles\n",
    "df2.loc[df2.title.duplicated(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot checking the titles.  They appear to be re-make.  Will keep the records.\n",
    "df2[(df2['title'] == 'Aladdin') | (df2['title'] == 'Rampage') | (df2['title'] == 'The Addams Family')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nan value (data cleaning process)\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the NaN in the release_date column as reported above\n",
    "df2.loc[df2.release_date.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Since we are intertested in 'original_language' = en, we will drop zh and ta\n",
    "# 2) lookk up the release_date for the other two movies online, index id 4873 & 6421\n",
    "\n",
    "# Remove row 1333 & 9056\n",
    "df2.drop(index=[1333, 9056], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that zh & ta are in fact removed\n",
    "df2.loc[df2.release_date.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Both 4873 and 6421 are 2020 films and has yet to anounce a release date set in 2020.  Remove from df.\n",
    "df2.drop(index=[4873, 6421], axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re check isnull status\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function get_movie_bud_rev explantions:\n",
    "\n",
    "The TMDB API also provide a way to get more details about a movie, suh as the revenue and budget data, which are not included in the initial data gathering. They are crucial in our analysis.\n",
    "We can slightly modify the function get_mtdb_movies to achieve this goal by changing the url parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to send request to pull movie details.  Interested in the revenue and the budget values\n",
    "def get_movie_bud_rev(movieid,rev_bud='revenue'):\n",
    "    '''\n",
    "    Init signature:\n",
    "        get_movie_bud_rev(movie_id, rev_bud='revenue')\n",
    "    Docstring:     \n",
    "        get_movie_bud_rev(movie_id, rev_bud='revenue') -> dict\n",
    "        Retrieve the revenue (default) or the budget info from the reponse object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_id: \n",
    "        TMDB movie id as int\n",
    "    rev_bud: \n",
    "        A string input (revenue | budget) to represent the dictionary key to search in the response object\n",
    "\n",
    "    '''\n",
    "    # define get request parameters\n",
    "    url = 'https://api.themoviedb.org/3/movie/' + str(movieid) + '?'\n",
    "    url_param = {\n",
    "                    'api_key': api_key,\n",
    "                    'language': 'en-US',\n",
    "                }\n",
    "    resp = requests.get(url, params=url_param)\n",
    "    if resp.status_code == 200:\n",
    "        resp_bud_rev = resp.json()[rev_bud]\n",
    "    else:\n",
    "        resp_bud_rev = np.nan\n",
    "  \n",
    "        \n",
    "    return resp_bud_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the revenue columns in the dataframe and populate the column using the get_movie_bud_rev function\n",
    "df2['revenue'] = df2['id'].apply(lambda x: get_movie_bud_rev(x, 'revenue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the budget column in the dataframe and populate the column using the get_movie_bud_rev function\n",
    "df2['budget'] = df2['id'].apply(lambda x: get_movie_bud_rev(x, 'budget'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview revenue & budget column \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NAN in revenue & budget coliumns\n",
    "df2.revenue.isnull().sum(), df2.budget.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the row to decide what to do\n",
    "df2.loc[df2.revenue.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the movie title is missing a lot of useful info, drop the row\n",
    "df2.drop(index=[2599], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Function get_genre explanation:\n",
    "\n",
    "The genre classification are represented by interger ID. In order to translate to more meaning terms, we need to retrieve the corresponding name for those IDs.\n",
    "API is available to pull this genre titles.\n",
    "get_genre has the similar structure as get_movie_bud_rev function. We only need to modify the URL to extract the genre names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the genre id classification from TMDB web site\n",
    "def get_genre():\n",
    "    '''\n",
    "    Init signature:\n",
    "        get_genre()\n",
    "    Docstring:\n",
    "        get_genre() -> dict\n",
    "        Retrieve the genre IDs and names stored as key:value dictionary.\n",
    "    Parameters:\n",
    "        none\n",
    "    \n",
    "    '''\n",
    "    # Create the response object\n",
    "    g_resp = requests.get(\n",
    "        'https://api.themoviedb.org/3/genre/movie/list?api_key='\n",
    "        + str(api_key) + '&language=en-US'\n",
    "        )\n",
    "    # if get request is successful, store genres name in dict.\n",
    "    if g_resp.status_code == 200:\n",
    "        genre_dict =  sorted(g_resp.json()['genres'], key=lambda x: x['id'])\n",
    "        \n",
    "    return genre_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function match_genre_id Explantions:\n",
    "\n",
    "This function will retrieve the genre id list from the dataframe as the first step.\n",
    "In a nested for loop, it retrieves the first element in the id to name mapping dictionary. Next it loop through the genre id list to find the matching key.\n",
    "If key matched, it append the key value to the genre_name list object, which will be returned by the function to populate the new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map TMDB genre_id to genre_name\n",
    "def match_genre_id(gid):\n",
    "    '''\n",
    "    Init signature:\n",
    "        match_genre_id(gid)\n",
    "    Docstring:\n",
    "        match_genre_id(gid) -> list\n",
    "        Take input genre id and match it to the \"genre id:genre name\" dict to retrieve the genre name\n",
    "    Parameters:\n",
    "        gid: The value in the genre_id column of the dataframe\n",
    "    '''\n",
    "    # Initiate an empty list to store the matching genre name\n",
    "    genre_name = []\n",
    "    # call get_genre function to pull the genre id/name from TMDB\n",
    "    genre_dict = get_genre()\n",
    "    # Match gerne id to pull gerne name\n",
    "    for i in gid:\n",
    "        for j in genre_dict:\n",
    "            if j['id'] == i:\n",
    "                genre_name.append(j['name'])\n",
    "    \n",
    "    return genre_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new coluimn to store genre_name\n",
    "df2['genre_names'] = df2['genre_ids'].apply(lambda x: match_genre_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took 20 min to run match_genre_id, create a backup\n",
    "df2.to_csv('add_genre_name_tmdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column release_date from string to datatime data type\n",
    "import datetime\n",
    "\n",
    "df2['release_date'] = pd.to_datetime(df2['release_date'])\n",
    "\n",
    "# Note to self: above method is more useful in comparison to using str yyyy-mm-dd to str yyyy\n",
    "# df2['release_date'] = df2['release_date'].map(lambda x: x[0:4] if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide revenue column by 1,000,000 for easy readability and graphing\n",
    "df2['revenue'] = round(df2['revenue'].div(1000000),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide budget column by 1,000,000 for easy readability and graphing\n",
    "df2['budget'] = round(df2['budget'].div(1000000),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataframe for safeguard\n",
    "df2.to_csv('final_tmdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More cleaning and merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the two csv files\n",
    "df = pd.read_csv('movieData.csv')\n",
    "df2 = pd.read_csv('final_tmdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the column titles a bit\n",
    "df2.columns = map(str.title, df2.columns)\n",
    "df2.rename(columns={'Genre_Names':'Genre'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the column titles and grab the year from release date so we an merge on title and year\n",
    "df2['Year']=df2['Release_Date']\n",
    "df2.dropna(subset = ['Year'], inplace = True)\n",
    "df2['Year']=df2['Year'].apply(lambda x: x[0:4])\n",
    "df2['Year']=df2['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes\n",
    "merged = pd.merge(left = df, right = df2, on=['Title', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop some superfluous columns\n",
    "merged.drop(['Id','Original_Language','Original_Title','Genre_Ids','Genre_y'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column\n",
    "merged.rename(columns={'Genre_x':'Genre'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up extra characters from stars columns\n",
    "merged['Stars'] = merged['Stars'].apply(lambda x:x.strip('['))\n",
    "merged['Stars'] = merged['Stars'].apply(lambda x:x.strip(']'))\n",
    "merged['Stars'] = merged['Stars'].apply(lambda x:x.replace(\"'\",''))\n",
    "merged['Stars'] = merged['Stars'].apply(lambda x:x.replace(\"  \",' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export merged dataframe\n",
    "merged.to_csv('mergedData.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
